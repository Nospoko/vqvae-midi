train:
  batch_size: 64
  epochs: 3
  log_interval: 10
  lr: 2e-4

logger:
  results_path: "results/"
  checkpoint_path: "checkpoints/"
  enable_wandb: False

system:
  device: "cuda:0"
  seed: 42

model:
  # Structure/Architecture
  output_features_filters: 2
  augment_output_features: False
  input_features_filters: 2  # Aligned with the number of channels
  augment_input_features: False
  output_features_dim: 1000  # Features size post decoding
  input_features_dim: 1000  # Aligned with the number of data points in each channel
  input_features_type: 'mfcc'
  # Encoder-Decoder details
  num_hiddens: 64
  num_residual_layers: 2
  num_residual_hiddens: 64
  use_kaiming_normal: True
  # VQ details
  embedding_dim: 100 # We might want to lower this value in the future, size of embedding vectors
  num_embeddings: 32 # K, needs empirical tuning
  commitment_cost: 0.25
  decay: 0.99
  # Misc
  use_jitter: False
  jitter_probability: 0.12
  record_codebook_stats: False
  verbose: False

run_date: ${now:%Y_%m_%d_%H_%M}
run_name: ${model.num_embeddings}embeddings_${model.embedding_dim}dim_${model.num_hiddens}hidden
